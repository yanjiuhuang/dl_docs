# Deep Feedforward Networks
深度前向反馈网络也被称为前向反馈神经网络(feedforward neural networks)或者多层感知器(MLP), 是最为精髓的深度学习模型。前向反馈网络的目标就是去估计一些函数$f*$。例如一个分类器, $y=f^*(x)$将一个输入$x$映射到一个类别$y$。一个前向反馈网络定义了一个映射$y=f(x;\theta)$并通过学习参数$\theta$来实现最好的函数估计。  

这些网络之所以被称为“神经网络”是因为受到神经科学的启发。网络的各个隐藏层通常都是以向量来作为值的。隐藏层的维度决定了模型的宽度。向量的各个元素可以被认为就是神经元。我们可以认为每一层都由多个并行的单元(unit)组成，每个单元都是是一个vector-to-scalar的函数。与神经元相似，每个单元接受来自于其他单元的输出来计算自己的激活值(activation value)。虽然最开始神经网络是受到神经科学的启发，但是现在数学和工程原理成为了引导神经网络研究的主要依据，并且模拟人脑也不再试神经网络的目标了。神经网络更像是一个函数估计的机器，来实现统计上的泛化能力。  

理解前向反馈网络可以先从考虑如何克服线性模型的限制入手。例如logistic regression和linear regression，线性模型由于可以通过闭合接或者凸包优化(convex optimization)易于拟合和可靠性成为了比较使用的模型。但是线性模型的显著不足就是模型容量较小，只限制于线性函数。所以线性模型无法理解输入变量之间的交互。  

为了扩展线性模型来表示输入数据$x$的非线性函数，我们可以将线性模型应用到输入数据的一个变换$\phi(x)$上，而不是$x$本身。其中$\phi(x)$就是一个非线性变换。这里我们可以认为$\phi$是提供了输入数据$x$的特征集，或者生成一个新的表示。  

那么如何选择这个变换$\phi$呢？  

1. 一种选择就是使用一种非常通用的变换$\phi$，例如无限维度$\phi$。这个变换已经在RBF核函数中被隐式地使用。如果$\phi(x)$具有足够高维度，那么我们就有足够的能力来拟合训练集。但是在测试集上的泛化能力仍然较差。非常基本特征映射通常是基于局部平滑的原则，并没有编码足够的先验信息来解决复杂问题。  
2. 另一个选择是手动调试$\phi$。在深度学习到来之前，这就是主要的方法。这种方法就需要大量的人力针对不同的任务进行调试。并且不同的领域，例如语音识别和计算机视觉，之间基本没有什么通性。
3. 使用深度学习的策略来学习$\phi$。这个方法中会定义一个模型$y=f(x;\theta, \omega)=\phi(x;\theta)^T\omega$。我们需要从一个宽泛的函数类中学习参数$\phi$以及将$\phi(x)$映射到目标输出的参数$\theta$。这就是一个前向反馈的例子。$\phi$定义了一个隐藏层。这个方法是三个中仅有的放弃利用训练问题的凸包性，但是带来的优势还是大于不足的。

我们先从一个前向反馈网络开始。

## 例子：学习XOR
XOR函数是一个二元操作，对于两个值$x_1, x_2$，只有当两个数中的一个数为1时，结果返回1，否则返回0。我们的模型提供一个函数$y = f(x; \theta)$和学习算法来调整参数$\theta$使$f$尽可能地与XOR所提供的函数$f^*$相似。  

在这个例子中我们不会在意统计上的泛化，而是对四个数据点$\mathbb{X} = \{[0, 0]^T,[0, 1]^T,[1, 0]^T,[1, 1]^T\}$进行准确的推断。主要的挑战就是如何拟合训练集。  

这里我们以回归问题的方法来处理，使用一个均值平法差(MSE)来作为损失函数。使用MSE的原因主要是为了简化模型的数学计算。当然还有其他更合适的方法来对二进制数据进行建模。  
我们使用MSE损失函数来评价整个训练集:  
$$J(\theta) = \frac{1}{4} \sum_{x\in\mathbb{X}}(f^*(x) - f(x;\theta))^2$$
这里我们就要确定我们模型的函数形式，$f(x;\theta)$。假如我们先使用一个线性模型：  
$$f(x;\theta) = x^Tw + b$$
这里的$\theta$参数空间由$w$和$b$两个组成。我们可以根据$w$和$b$使用等式求解的方法来最小化$J(\theta)$。最后的结果就是$w=0, b=\frac{1}{2}$，而这样模型就会总是输出0.5。通过[图1]()就能知道线性模型是不能表示XOR函数的。一种解决办法就是使用一个能够学习不同特征空间的模型，而在这个空间中可以使用线性模型来表示问题的解。  

我们的模型总是需要更多的空间  

在这个例子中，我们简单地指定了最后的解，并通过计算表明其零误差。在真实应用中，可能有十亿以上的参数和训练样本。所以不可能简单地通过猜测来获得答案。我们可以使用基于梯度优化算法来寻找参数，并且维持在一个较小的误差。XOR例子中采用的是一个全局范围损失函数最小化的方法，梯度下降会逐渐收敛到那个极值点。当然还存在其他等效的解决XOR问题的方法，但是都可以使用梯度下降的办法来解决。梯度下降最后收敛的点取决于权重设置的初始值。实际中梯度下降一般不会找到简洁的，易于理解的整型值的解。  

## 基于梯度的学习
神经网络和线性模型之间的最大区别就是神经网络的非线性所导致的损失函数非凸包性。这意味着神经网络通常使用基于梯度的迭代优化子来驱动损失函数收敛到一个非常低的值。不同于神经网络，我们就会使用解析线性等式的方式来训练线性回归模型，以及使用带有全局收敛保证的凸包优化算法来训练logistic回归和SVM。凸包优化可以从任意初始值开始收敛(虽然这种方法非常健壮，但是仍然存在数值问题)。应用到非凸包损失函数的随机梯度下降(SGD)就没有收敛保证，并且对初始值敏感。对于前向反馈神经网络，将初始值设置为小随机数，以及将偏倚(bias)设置为0或者小的正整数是比较重要的。很多算法的提升和优化都是基于梯度下降的思想，尤其是随机梯度下降。  

当然我们也可以使用梯度下降的方法来训练线性回归和SVM，特别是在数据集很大的情况下会比较普遍。这样来看，训练神经网络和其他机器学习模型是没有什么区别的。计算神经网络的梯度则相对复杂一些，但是仍然可以做到比较高效和准确。  

跟其他机器学习模型一样，使用梯度下降的学习必需要选择一个损失函数(cost function)，以及如何来表示模型的输出。  

### 损失函数
设计一个深度神经网络的重要方面就是损失函数的选择。幸运地神经网络的损失函数多多少少与参数模型的损失函数一样，例如线性模型。在大部分情况下，参数模型定义了一个分布$p(y | x; \theta)$以及采用最大似然的原理。这个意味着要使用训练数据和模型预测之间的交叉熵来作为损失函数。  

有时候我们会使用更简单的方法。不去预测完整的对$y$的概率分布，而只是预测条件于$x$的y的统计值。这样特例化的损失函数使得我们可以训练这些估计的预算子。  

完整训练神经网络的损失函数通常是一个主损失函数和一个正则项(regularization)的组合。线性模型中使用的权值衰减(weight decay)也同样可以适用于深度神经网络，也是目前最流行的正则化策略。  

#### 使用最大似然学习条件分布
大部分现代神经网络都是使用最大似然来训练的，那么损失函数就是log-likelihood的负值形式。这个等同于描述为训练集数据和模型分布之间的交叉熵。以下就是神经网络的损失函数：  

$$J(\theta) = - \mathbb{E}_{x,y\sim \hat{p_{data}}}\log p_{model}(y|x)$$
这个损失函数的具体形式会随着不同的模型而改变，具体的变化还是在于$\log p_{model}$的形式。上述公式的展开会得到一些与模型参数无关项，而这些就是可以被忽略的。我们就以$p_{model}(y | x)=\mathcal{N}(y; f(x;\theta), I)$为例子，损失函数就可以展开为如下形式：  

$$J(\theta) = \frac{1}{2} \mathbb{E}_{x,y\sim \hat{p_{data}}}\lVert y - f(x;\theta)\lVert^2 + const$$




# Reference
[1] [RBF核函数](http://baike.baidu.com/link?url=P35OBfXNjmZEysUJFLmelk_UjnR9Vu7hwybcCJrevqNkSe5gUufN8Hb8M8pxBuFpS9K6ljlS_wvJoHEYjsKieqtlOnit4gJVkU_45nDE4xH6KOdw6fyDGDDn20E1deuG6jweic_IeeAVQZv0BD4W__):   
[2] [Non-convex and convex]():  
[3] [最大似然估计和最小二乘的理解](https://www.zhihu.com/question/20447622)， [最大似然估计的介绍](https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1)  
[4] 

