# Deep Feedforward Networks（168 -- 227）
深度前向反馈网络也被称为前向反馈神经网络(feedforward neural networks)或者多层感知器(MLP), 是最为精髓的深度学习模型。前向反馈网络的目标就是去估计一些函数$f*$。例如一个分类器, $y=f^*(x)$将一个输入$x$映射到一个类别$y$。一个前向反馈网络定义了一个映射$y=f(x;\theta)$并通过学习参数$\theta$来实现最好的函数估计。  

这些网络之所以被称为“神经网络”是因为受到神经科学的启发。网络的各个隐藏层通常都是以向量来作为值的。隐藏层的维度决定了模型的宽度。向量的各个元素可以被认为就是神经元。我们可以认为每一层都由多个并行的单元(unit)组成，每个单元都是是一个vector-to-scalar的函数。与神经元相似，每个单元接受来自于其他单元的输出来计算自己的激活值(activation value)。虽然最开始神经网络是受到神经科学的启发，但是现在数学和工程原理成为了引导神经网络研究的主要依据，并且模拟人脑也不再试神经网络的目标了。神经网络更像是一个函数估计的机器，来实现统计上的泛化能力。  

理解前向反馈网络可以先从考虑如何克服线性模型的限制入手。例如logistic regression和linear regression，线性模型由于可以通过闭合接或者凸包优化(convex optimization)易于拟合和可靠性成为了比较使用的模型。但是线性模型的显著不足就是模型容量较小，只限制于线性函数。所以线性模型无法理解输入变量之间的交互。  

为了扩展线性模型来表示输入数据$x$的非线性函数，我们可以将线性模型应用到输入数据的一个变换$\phi(x)$上，而不是$x$本身。其中$\phi(x)$就是一个非线性变换。这里我们可以认为$\phi$是提供了输入数据$x$的特征集，或者生成一个新的表示。  

那么如何选择这个变换$\phi$呢？  

1. 一种选择就是使用一种非常通用的变换$\phi$，例如无限维度$\phi$。这个变换已经在RBF核函数中被隐式地使用。如果$\phi(x)$具有足够高维度，那么我们就有足够的能力来拟合训练集。但是在测试集上的泛化能力仍然较差。非常基本特征映射通常是基于局部平滑的原则，并没有编码足够的先验信息来解决复杂问题。  
2. 另一个选择是手动调试$\phi$。在深度学习到来之前，这就是主要的方法。这种方法就需要大量的人力针对不同的任务进行调试。并且不同的领域，例如语音识别和计算机视觉，之间基本没有什么通性。
3. 使用深度学习的策略来学习$\phi$。这个方法中会定义一个模型$y=f(x;\theta, \omega)=\phi(x;\theta)^T\omega$。我们需要从一个宽泛的函数类中学习参数$\phi$以及将$\phi(x)$映射到目标输出的参数$\theta$。这就是一个前向反馈的例子。$\phi$定义了一个隐藏层。这个方法是三个中仅有的放弃利用训练问题的凸包性，但是带来的优势还是大于不足的。

我们先从一个前向反馈网络开始。

## 例子：学习XOR
XOR函数是一个二元操作，对于两个值$x_1, x_2$，只有当两个数中的一个数为1时，结果返回1，否则返回0。我们的模型提供一个函数$y = f(x; \theta)$和学习算法来调整参数$\theta$使$f$尽可能地与XOR所提供的函数$f^*$相似。  

在这个例子中我们不会在意统计上的泛化，而是对四个数据点$\mathbb{X} = \{[0, 0]^T,[0, 1]^T,[1, 0]^T,[1, 1]^T\}$进行准确的推断。主要的挑战就是如何拟合训练集。  

这里我们以回归问题的方法来处理，使用一个均值平法差(MSE)来作为损失函数。使用MSE的原因主要是为了简化模型的数学计算。当然还有其他更合适的方法来对二进制数据进行建模。  
我们使用MSE损失函数来评价整个训练集:  
$$J(\theta) = \frac{1}{4} \sum_{x\in\mathbb{X}}(f^*(x) - f(x;\theta))^2$$
这里我们就要确定我们模型的函数形式，$f(x;\theta)$。假如我们先使用一个线性模型：  
$$f(x;\theta) = x^Tw + b$$
这里的$\theta$参数空间由$w$和$b$两个组成。我们可以根据$w$和$b$使用等式求解的方法来最小化$J(\theta)$。最后的结果就是$w=0, b=\frac{1}{2}$，而这样模型就会总是输出0.5。通过[图1]()就能知道线性模型是不能表示XOR函数的。一种解决办法就是使用一个能够学习不同特征空间的模型，而在这个空间中可以使用线性模型来表示问题的解。  

我们的模型总是需要更多的空间  

在这个例子中，我们简单地指定了最后的解，并通过计算表明其零误差。在真实应用中，可能有十亿以上的参数和训练样本。所以不可能简单地通过猜测来获得答案。我们可以使用基于梯度优化算法来寻找参数，并且维持在一个较小的误差。XOR例子中采用的是一个全局范围损失函数最小化的方法，梯度下降会逐渐收敛到那个极值点。当然还存在其他等效的解决XOR问题的方法，但是都可以使用梯度下降的办法来解决。梯度下降最后收敛的点取决于权重设置的初始值。实际中梯度下降一般不会找到简洁的，易于理解的整型值的解。  

## 基于梯度的学习
神经网络和线性模型之间的最大区别就是神经网络的非线性所导致的损失函数非凸包性。这意味着神经网络通常使用基于梯度的迭代优化子来驱动损失函数收敛到一个非常低的值。不同于神经网络，我们就会使用解析线性等式的方式来训练线性回归模型，以及使用带有全局收敛保证的凸包优化算法来训练logistic回归和SVM。凸包优化可以从任意初始值开始收敛(虽然这种方法非常健壮，但是仍然存在数值问题)。应用到非凸包损失函数的随机梯度下降(SGD)就没有收敛保证，并且对初始值敏感。对于前向反馈神经网络，将初始值设置为小随机数，以及将偏倚(bias)设置为0或者小的正整数是比较重要的。很多算法的提升和优化都是基于梯度下降的思想，尤其是随机梯度下降。  

当然我们也可以使用梯度下降的方法来训练线性回归和SVM，特别是在数据集很大的情况下会比较普遍。这样来看，训练神经网络和其他机器学习模型是没有什么区别的。计算神经网络的梯度则相对复杂一些，但是仍然可以做到比较高效和准确。  

跟其他机器学习模型一样，使用梯度下降的学习必需要选择一个损失函数(cost function)，以及如何来表示模型的输出。  

### 损失函数
设计一个深度神经网络的重要方面就是损失函数的选择。幸运地神经网络的损失函数多多少少与参数模型的损失函数一样，例如线性模型。在大部分情况下，参数模型定义了一个分布$p(y | x; \theta)$以及采用最大似然的原理。这个意味着要使用训练数据和模型预测之间的交叉熵来作为损失函数。  

有时候我们会使用更简单的方法。不去预测完整的对$y$的概率分布，而只是预测条件于$x$的y的统计值。这样特例化的损失函数使得我们可以训练这些估计的预算子。  

完整训练神经网络的损失函数通常是一个主损失函数和一个正则项(regularization)的组合。线性模型中使用的权值衰减(weight decay)也同样可以适用于深度神经网络，也是目前最流行的正则化策略。  

#### 使用最大似然学习条件分布
大部分现代神经网络都是使用最大似然来训练的，那么损失函数就是log-likelihood的负值形式。这个等同于描述为训练集数据和模型分布之间的交叉熵。以下就是神经网络的损失函数：  

$$J(\theta) = - \mathbb{E}_{x,y\sim \hat{p_{data}}}\log p_{model}(y|x)$$
这个损失函数的具体形式会随着不同的模型而改变，具体的变化还是在于$\log p_{model}$的形式。上述公式的展开会得到一些与模型参数无关项，而这些就是可以被忽略的。我们就以$p_{model}(y | x)=\mathcal{N}(y; f(x;\theta), I)$为例子，损失函数就可以展开为如下形式：  

$$J(\theta) = \frac{1}{2} \mathbb{E}_{x,y\sim \hat{p_{data}}}\lVert y - f(x;\theta)\lVert^2 + const$$

其中$\frac{1}{2}$系数和不依赖于$\theta$的计算项。正如我们所知道的，输出分布的最大似然估计和线性模型的MSE之间的等效性。但是事实上这个等效性是跟选择的函数$f(x;\theta)$无关。对最大似然损失函数进行求导减少对模型设计损失函数的负担。指定一个模型$p(y|x)$就自动了确定了一个损失函数$\log p(y|x)$。  

在神经网络的设计中，我们需要损失函数的梯度比较大以及有足够的预测能力来引导整个的学习。饱和(saturate)的函数会破坏这个目标，因为它会使梯度比较小。在很多情况下还是会发生这种情况的。因为隐藏层的激活函数或者输出单元是饱和的。对于很多模型，负对数似然(negative log-likelihood)有助于避免这个问题。很多输出单元会涉及到exp函数，而它在参数高负值的时候就是饱和的。对数函数能够抵消输出单元的exp。这里我们可以看出损失函数和输出单元的选择是有联系的。  

在实际模型的应用中，用于进行最大似然估计的交叉熵损失有一个不寻常特性就是通常没有一个最小值。对于离散的输出变量，大多数模型是以无法表示0或者1概率的方式来参数化的，但是可以实现任意的接近。逻辑回归就是这样一个例子。对于实数输出变量，如果模型能够控制输出分布的密度，那么就有该正确的训练集输出赋予较高的密度。这样就会导致交叉熵会接近负无穷大。这里我们就需要使用正则化技术来避免模型获得这样方式所带来的无限量奖励。  

##### 学习条件统计值

不同于学习一个全概率分布$p(y|x;\theta)$，通常我们想要学习给定$x$对应$y$的条件统计值。例如我们有一个预测算子$f(x; \theta)$用于预测$y$的均值。  

如果我们使用一个足够强大的神经网络，可以认为它就有能力表示一个较大范围类型的函数。这里的函数类型只会由连续性和上下界等特征来限制，而不会有特定的参数形式。从这点来看。我们可以认为损失函数就是一个泛函，而不只是一个函数。一个泛函就是一个将函数到实数的映射。所以学习就是选择函数，而不是选择参数集。我们可以设计损失泛函在特定函数有它的最小值。例如我们设计损失泛函在某个函数上有其最小值，而这个函数将$x$映射到给定$x$对应$y$的期望值上。解一个关于函数的优化问题需要一个叫变分法(calculus of variations)的数学工具。当然目前没有必要完全理解这个变分法，而只需要知道可以使用变分法来推出以下的两个结果。  

第一个结果就是解决如下优化问题：  
$$f^*=\arg \min_f \mathbb{E}_{x,y\sim p_{data}} \lVert y - f(x)\lVert^2$$
只要目标函数在我们优化覆盖的类别中，就可以生成如下等式：  
$$f^*=\mathbb{E}_{x,y\sim p_{data}(y|x)} [y]$$
也就是说如果我们可以从真实数据分布中训练无限多的样本，可以由最小化MSE损失函数学习出一个预测给定$x$对应$y$均值的函数。不同损失函数给出不同的统计值。  
使用变分法的第二个结果就是只要可以被我们优化函数族来描述，如下等式就可以学习一个函数来预测$y$的中值(median value)。这个函数通常被称为平均绝对误差(mean absolute error)。  

不幸运地是MSE和MAE在基于梯度的优化中经常会导致较差的结果。一些饱和的输出单元与这些损失函数结合在一起时会产生非常小的梯度。这就是为什么即使在没有必要估计一个完成分布$p(y|x)$时交叉熵也比它们更流行的原因。  

#### 输出单元
损失函数的选择与输出单元的选择联系紧密。绝大部分时候我们可以在真实数据分布和模型分布之间使用交叉熵。如何表示输出决定了交叉熵的形式。任何类型的神经网络单元都可以被用于作为输出单元或者隐藏单元。输出层的作用就是就是对特征进行最后的转化来完成任务。  

##### 针对高斯输出分布的线性单元
基于一个线性仿射变换的输出单元就是一种较为简单的输出单元。通常我们就直接称它为线性单元(linear units)。给定特征$h$，线性单元层会产生一个向量$\hat{y}=W^Th + b$。线性单元层通常被用来生成条件高斯分布的均值：  
$$p(y|x)=\mathcal{N}(y;\hat{y}, I)$$
这里最大化对数似然率则等同于最小化均值平方差(MSE)。可以使用最大似然框架来学习高斯的方差，但是这里方差必需被限制为所有输入的正定矩阵。在实践中这个限制是很难满足的，所以通常会使用其他的输出单元来参数化方差。下文我们会简单地介绍一下如何对方差建模。由于线性单元的不饱和性，所以可以广泛地应用到基于梯度的优化算法中。  

一个Sigmoid输出单元采用如下方式来定义
$$\hat{y}=\sigma(w^Th+b)$$
其中$\sigma$就是logistic sigmoid函数：$\sigma(x)=\frac{1}{1+e^{-x}}$。  
我们可以认为sigmoid输出单元有两个组成部分。首先它使用了一个线性层来计算$z=w^Th + b$。然后它使用了sigmoid激活函数将$z$转换成一个概率值。  

这里我们先跳过$x$来直接讨论如何使用$z$来定义关于$y$的概率分布。Sigmoid可以使用一个没有经过规范化的分布$\hat{P}(y)$，也就是这个分布的概率总和不为1。为了实现规范化，可以通过除以一个常数。

##### 针对Bernoulli输出分布的Sigmoid单元
许多任务要求对二进制的值进行预测，例如二分类问题。最大似然方法就是用来定义条件于$x$的$y$Bernoulli分布。一个Bernoulli分布可以被单一的数来定义。神经网络只需要用来预测$P=(y=1 | x)$。而这个数的取值就在范围$[0, 1]$之间。  

为了满足这个条件，我们需要进行一些设计。假定我们使用一个线性单元。通过阈值化可以得到一个有效的概率值。  
$$P(y=1|x) = max\{0, min\{1, w^Th + b\}\}$$
但是这个方法是无法使用梯度下降的办法来训练的。一旦$w^Th+b$的取值超出了$[0,1]$的范围，那么梯度就会是0。这样就无法继续训练下去了。  

所以我们需要采用其他的办法来确保即使模型产生了错误的值，它总是有较好的梯度。而这个办法就是使用结合了最大似然的Sigmoid输出单元。

一个Sigmoid输出单元采用如下方式来定义
$$\hat{y}=\sigma(w^Th+b)$$
其中$\sigma$就是logistic sigmoid函数：$\sigma(x)=\frac{1}{1+e^{-x}}$。  
我们可以认为sigmoid输出单元有两个组成部分。首先它使用了一个线性层来计算$z=w^Th + b$。然后它使用了sigmoid激活函数将$z$转换成一个概率值。  

这里我们先跳过$x$来直接讨论如何使用$z$来定义关于$y$的概率分布。Sigmoid可以使用一个没有经过规范化的分布$\hat{P}(y)$，也就是这个分布的概率总和不为1。为了实现规范化，可以通过除以一个常数。如果我们从假定非规范化概率对于$y$和$x$是线性的，那么我们就可以通过对其指数化来获得非规范化概率。然后我们就会发现规范化可以产生一个基于Sigmoid化的变量$z$的Bernoulli分布：  
$$\log \hat{P}(y)=yz$$
$$\hat{P} = exp(yz)$$
$$P(y) = \frac{exp(yz)}{\sum_{y'}^{1} exp(y'z)}$$
$$P(y) = \sigma((2y - 1)z)$$
在统计学中基于指数和规范化的概率分布是很常见的。我们会称这样定义了一个面向二进制变量的分布为$logit$。

在对数空间中这种用于预测概率的方法很自然地就会使用最大似然学习。因为损失函数采用如下形式：  
$$-\log P(y | x)$$
损失函数中的对数抵消了sigmoid中的指数。如果不这样，sigmoid的饱和性就是阻止基于梯度的学习向前进行。由Sigmoid参数化的Bernoulli分布可以使用如下形式的针对最大似然学习的损失函数：  
$$J(\theta) = - \log P(y | x)$$
$$\qquad \qquad =- \log \sigma((2y - 1)z)$$
$$\qquad =\zeta((1 - 2y)z)$$

这样我们就使用softplus重写了损失函数，就可以发现就有当$(1-2y)z$非常负的时候函数才会趋于饱和。这种情况只会发生在模型已经有正确答案时。当$z$得到错误的符号时，softplus的传参$(1-2y)z$就是简化为$|z|$。这时随着$|z|$变大，softplus函数就是趋向于简单地返回$|z|$。相对于$z$的导数就会趋向于$sign(z)$。所以在错误的$z$的情况下，softplus函数也不会收缩梯度。这个特性是很重要的，因为这样就能快速地纠正错误的$z$。  

如果我们使用其他的损失函数，那么损失就会在$\sigma(z)$饱和时也趋于饱和。对于sigmoid函数而言，当$z$变得很负或者很正时，函数的梯度就会趋于0。正是这个原因，训练sigmoid输出单元时更倾向使用最大似然来学习。  

在实际实现时，为了避免数值计算的问题，我们最好将负对数似然率作为$z$的函数，而不是$\hat{y}=\sigma(z)$的函数。如果sigmoid函数下溢出为0时，后者就会产生一个负无穷大的值。  

##### 针对多项式分布的Softmax单元
如果能够希望表示面向有$n$种取值的离散变量的概率分布，那么我们就可以使用softmax函数。这个函数可以认为是sigmoid函数的泛化。通常我们会使用softmax函数作为一个分类器的输出，来表示针对$n$种不同类别的概率分布。较少情况下也会在模型内部使用softmax。这时主要是用它来对某个内部变量的$n$种选项做出选择。  

所以我们需要产生一个向量$\hat{y}$，其中$\hat{y_i} = P(y=i|x)$。对于这个向量中的每个元素不只是要求在0-1之间，而且所有元素的总和要等于1。这样才代表一个有效的概率分布。首先我们先用一个线性层来预测非规范化对数概率:  
$$z=W^Th + b$$
其中$z_i = \log \hat{P}(y=i|x)$。然后softmax函数就可以指数化和规范化$z$来获得想要的$\hat{y}$。下面就是正式的softmax函数:
$$softmax(z)_i=\frac{exp(z_i)}{\sum_{j} exp(z_j)}$$

与logistic sigmoid函数一样，由于使用了指数函数，当将softmax作为输出单元时使用最大对数似然率就可以获得较好的训练性能。在这种情况下，我们就希望最大化$\log P(y=i; z) = \log softmax(z)_i$。而它的对数形式如下：
$$\log softmax(z)_i = z_i - \log \sum_j exp(z_j)$$
上述等式表明输入$z_i$对损失函数有直接的贡献。因为这项不会饱和,所以第二项$exp(z_i)$的梯度在变得很小时，这个学习仍然能继续进行。当最大化对数似然时，需要尽量增大第一项和减少第二项。在直觉上我们可以认为$\log \sum_j exp(z_j)$近似可以使用$\max_j z_j$来估计。如果正确的分类已经是softmax中最大的输出，那么$-z_i$就会被$\log \sum_j exp(z_j) \approx  max_j z_j=z_i$抵消掉。这个样本就会对最后的训练成本基本没有什么影响，而训练只会由被错误分类的样本所影响。  

上面只讨论了一个单一的样本。整体来说，非规范化的最大似然率将驱动模型去学习准确预测训练集中观察标记数据的参数：  

$$softmax(z(x; \theta))_i \approx \frac{\sum_{j=1}^{m} 1_{y^{(j)}=i,x^{(j)}=x}}{\sum_{j=1}^x 1_{x^{(j)}=x}}$$

因为最大似然率是一个一致性估计子，只要模型族能够表示训练集分布，那么我们就能够对多项式分布做出准确地预测。在实践中，有限的模型容量和不够完美的优化就意味着模型只能去估计接近这些分类。  

许多除了对数最大似然之外的目标函数与softmax单元结合在一起时都没有很好的性能。特别是对于那些没有使用log来抵消指数exp的目标函数。因为在exp的值为较大负值时，训练的梯度就会消失。特别是将平方误差作为损失函数，当模型做出高可信的错误预测时，很难再训练模型来修正这个错误。为了理解其他损失函数失败的原因，我们需要检视一下softmax函数本身。  

与sigmoid函数一样，softmax激活也是会饱和的。只有一个输出的sigmoid函数在正负值都很大时都会饱和。softmax函数有多个输出。当输出变量之间差距很大时，输出就会趋于饱和。当softmax函数饱和时，许多损失函数也会饱和。除非它们能够反转这个饱和的激活函数。由于softmax函数会对数量变量之间的不同，那么如果对所有的输入变量加上相同的标量，那么softmax函数的数据就会保持不变:  

$$softmax(z) = softmax(z + c)$$

使用这个性质，我们可以推导出一个稳定的变式:  
$$softmax(z) = softmax(z - \max_i z_i)$$

这样我们就可以避免出现数值计算的误差。因为当$z$是一个超大的负值时，很容易出现下溢的问题。从上面等式可以看出，softmax函数的输入变量统一都减去$\max_i z_i$的偏移量。  

当对应的输入是最大值($z_i = \max_i z_i$)以及远大于其他输入时，softmax函数的输出就会饱和于1。当对应的输入不是最大值并且最大值远大于它时，softmax函数的输出就会饱和于0。这是与sigmoid函数相似的通用性质。所以如果损失函数没有进行相应的补偿，那么就会给学习带来很大的难度。  

softmax的参数$z$可以有两种方式来产生。最为普遍的做法就是由网络的上一层来产生$z$中的每一个元素，例如之前描述使用线性层产生的结果$z=W^T h + b$。虽然很直接，但是这个方法实际上过参数化了目标分布。因为$n$个输出的和必需为1，这就意味着我们只需要$n - 1$个参数。第n个输出值只需要通过1减去前面n-1个值即可。我们可以要求最后一个元素为0。实际上在sigmoid函数来学习Bernoulli分布时就假定了$z_n=0$。 n个参数和n-1个参数的两个方法都可以用来学习同一个概率分布集合，只是会有不同的学习动态(learning dynamics)。在实践中两个方法基本没有什么区别，只是过参数化的版本更易于实现。  

从神经科学的角度来看，softmax创建了一种让参与的单元相互竞争的形式：由于总和为1，一个输出值的增加，就要减少其他的值。这个类似于神经科学中的侧抑制(lateral inhibition)。极端情况下就是winner-take-all。  

这里可能需要解释一下softmax这个名字。实际上它更接近与argmax，而不是max函数。其中的soft表示softmax函数是连续可微的，而argmax使用了one-hot向量来表示结果，所以不是连续和可微的。某种程度上我们可以认为softmax是一个软化的argmax函数。maximum函数对应的软化函数就是$softmax(z)^Tz$。所以我们更应该把softmax叫做'softargmax'。  

##### 其他输出单元类型





# Reference
[1] [RBF核函数](http://baike.baidu.com/link?url=P35OBfXNjmZEysUJFLmelk_UjnR9Vu7hwybcCJrevqNkSe5gUufN8Hb8M8pxBuFpS9K6ljlS_wvJoHEYjsKieqtlOnit4gJVkU_45nDE4xH6KOdw6fyDGDDn20E1deuG6jweic_IeeAVQZv0BD4W__):   
[2] [Non-convex and convex]():  
[3] [最大似然估计和最小二乘的理解](https://www.zhihu.com/question/20447622)， [最大似然估计的介绍](https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1)  
[4] [交叉熵损失函数](http://blog.csdn.net/u012162613/article/details/44239919): $C=-\frac{1}{n} \sum_{x} [y\ln a + (1-y)\ln(1 - a)]$将损失函数的梯度由依赖于目标函数$\sigma(x)$的梯度转成依赖于预测的误差$\sigma(x) - y$。这样就使得误差大的时候更新的比较块，误差小的时候更新慢。对数似然函数长用来作为softmax回归的损失函数。如果使使用sigmoid函数，那么就采用交叉熵损失函数。而在二类别时最大对数似然损失函数可以化简为交叉熵损失函数的形式。  
[5] [neural networks and deep learning](http://neuralnetworksanddeeplearning.com/)  
[6] 平均绝对误差: 统计学上用于评价预测值与真实值的接近程度。$$MAE=\frac{1}{n} \sum_{i=1}^n \vert f_i - y_i\vert $$  
[7] [Logit](https://en.wikipedia.org/wiki/Logit): [logit in reddit](https://www.reddit.com/r/MachineLearning/comments/37ardy/softmax_vs_sigmoid_for_output_of_a_neural_network/)，  
[8] [Consistent Estimator](https://en.wikipedia.org/wiki/Consistent_estimator): 在统计学中，一个一致性估计子(或者asymptotically consistent estimator)表明随着数据样本的无限增加，估计的结果序列会概率收敛到$\theta_0$。这就意味着估计结果的分布会越来越接近真实的值。  
[9] [overparametrize 过参数化](https://www.douban.com/note/92521266/)：可以使用dependency of parameters来衡量overparametrize的程度。  
[10] [one-hot](https://en.wikipedia.org/wiki/One-hot): 一位热码，独热码

