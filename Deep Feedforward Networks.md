# Deep Feedforward Networks（168 -- 227）
深度前向反馈网络也被称为前向反馈神经网络(feedforward neural networks)或者多层感知器(MLP), 是最为精髓的深度学习模型。前向反馈网络的目标就是去估计一些函数$f*$。例如一个分类器, $y=f^*(x)$将一个输入$x$映射到一个类别$y$。一个前向反馈网络定义了一个映射$y=f(x;\theta)$并通过学习参数$\theta$来实现最好的函数估计。  

这些网络之所以被称为“神经网络”是因为受到神经科学的启发。网络的各个隐藏层通常都是以向量来作为值的。隐藏层的维度决定了模型的宽度。向量的各个元素可以被认为就是神经元。我们可以认为每一层都由多个并行的单元(unit)组成，每个单元都是是一个vector-to-scalar的函数。与神经元相似，每个单元接受来自于其他单元的输出来计算自己的激活值(activation value)。虽然最开始神经网络是受到神经科学的启发，但是现在数学和工程原理成为了引导神经网络研究的主要依据，并且模拟人脑也不再试神经网络的目标了。神经网络更像是一个函数估计的机器，来实现统计上的泛化能力。  

理解前向反馈网络可以先从考虑如何克服线性模型的限制入手。例如logistic regression和linear regression，线性模型由于可以通过闭合接或者凸包优化(convex optimization)易于拟合和可靠性成为了比较使用的模型。但是线性模型的显著不足就是模型容量较小，只限制于线性函数。所以线性模型无法理解输入变量之间的交互。  

为了扩展线性模型来表示输入数据$x$的非线性函数，我们可以将线性模型应用到输入数据的一个变换$\phi(x)$上，而不是$x$本身。其中$\phi(x)$就是一个非线性变换。这里我们可以认为$\phi$是提供了输入数据$x$的特征集，或者生成一个新的表示。  

那么如何选择这个变换$\phi$呢？  

1. 一种选择就是使用一种非常通用的变换$\phi$，例如无限维度$\phi$。这个变换已经在RBF核函数中被隐式地使用。如果$\phi(x)$具有足够高维度，那么我们就有足够的能力来拟合训练集。但是在测试集上的泛化能力仍然较差。非常基本特征映射通常是基于局部平滑的原则，并没有编码足够的先验信息来解决复杂问题。  
2. 另一个选择是手动调试$\phi$。在深度学习到来之前，这就是主要的方法。这种方法就需要大量的人力针对不同的任务进行调试。并且不同的领域，例如语音识别和计算机视觉，之间基本没有什么通性。
3. 使用深度学习的策略来学习$\phi$。这个方法中会定义一个模型$y=f(x;\theta, \omega)=\phi(x;\theta)^T\omega$。我们需要从一个宽泛的函数类中学习参数$\phi$以及将$\phi(x)$映射到目标输出的参数$\theta$。这就是一个前向反馈的例子。$\phi$定义了一个隐藏层。这个方法是三个中仅有的放弃利用训练问题的凸包性，但是带来的优势还是大于不足的。

我们先从一个前向反馈网络开始。

## 例子：学习XOR
XOR函数是一个二元操作，对于两个值$x_1, x_2$，只有当两个数中的一个数为1时，结果返回1，否则返回0。我们的模型提供一个函数$y = f(x; \theta)$和学习算法来调整参数$\theta$使$f$尽可能地与XOR所提供的函数$f^*$相似。  

在这个例子中我们不会在意统计上的泛化，而是对四个数据点$\mathbb{X} = \{[0, 0]^T,[0, 1]^T,[1, 0]^T,[1, 1]^T\}$进行准确的推断。主要的挑战就是如何拟合训练集。  

这里我们以回归问题的方法来处理，使用一个均值平法差(MSE)来作为损失函数。使用MSE的原因主要是为了简化模型的数学计算。当然还有其他更合适的方法来对二进制数据进行建模。  
我们使用MSE损失函数来评价整个训练集:  
$$J(\theta) = \frac{1}{4} \sum_{x\in\mathbb{X}}(f^*(x) - f(x;\theta))^2$$
这里我们就要确定我们模型的函数形式，$f(x;\theta)$。假如我们先使用一个线性模型：  
$$f(x;\theta) = x^Tw + b$$
这里的$\theta$参数空间由$w$和$b$两个组成。我们可以根据$w$和$b$使用等式求解的方法来最小化$J(\theta)$。最后的结果就是$w=0, b=\frac{1}{2}$，而这样模型就会总是输出0.5。通过[图1]()就能知道线性模型是不能表示XOR函数的。一种解决办法就是使用一个能够学习不同特征空间的模型，而在这个空间中可以使用线性模型来表示问题的解。  

我们的模型总是需要更多的空间  

在这个例子中，我们简单地指定了最后的解，并通过计算表明其零误差。在真实应用中，可能有十亿以上的参数和训练样本。所以不可能简单地通过猜测来获得答案。我们可以使用基于梯度优化算法来寻找参数，并且维持在一个较小的误差。XOR例子中采用的是一个全局范围损失函数最小化的方法，梯度下降会逐渐收敛到那个极值点。当然还存在其他等效的解决XOR问题的方法，但是都可以使用梯度下降的办法来解决。梯度下降最后收敛的点取决于权重设置的初始值。实际中梯度下降一般不会找到简洁的，易于理解的整型值的解。  

## 基于梯度的学习
神经网络和线性模型之间的最大区别就是神经网络的非线性所导致的损失函数非凸包性。这意味着神经网络通常使用基于梯度的迭代优化子来驱动损失函数收敛到一个非常低的值。不同于神经网络，我们就会使用解析线性等式的方式来训练线性回归模型，以及使用带有全局收敛保证的凸包优化算法来训练logistic回归和SVM。凸包优化可以从任意初始值开始收敛(虽然这种方法非常健壮，但是仍然存在数值问题)。应用到非凸包损失函数的随机梯度下降(SGD)就没有收敛保证，并且对初始值敏感。对于前向反馈神经网络，将初始值设置为小随机数，以及将偏倚(bias)设置为0或者小的正整数是比较重要的。很多算法的提升和优化都是基于梯度下降的思想，尤其是随机梯度下降。  

当然我们也可以使用梯度下降的方法来训练线性回归和SVM，特别是在数据集很大的情况下会比较普遍。这样来看，训练神经网络和其他机器学习模型是没有什么区别的。计算神经网络的梯度则相对复杂一些，但是仍然可以做到比较高效和准确。  

跟其他机器学习模型一样，使用梯度下降的学习必需要选择一个损失函数(cost function)，以及如何来表示模型的输出。  

### 损失函数
设计一个深度神经网络的重要方面就是损失函数的选择。幸运地神经网络的损失函数多多少少与参数模型的损失函数一样，例如线性模型。在大部分情况下，参数模型定义了一个分布$p(y | x; \theta)$以及采用最大似然的原理。这个意味着要使用训练数据和模型预测之间的交叉熵来作为损失函数。  

有时候我们会使用更简单的方法。不去预测完整的对$y$的概率分布，而只是预测条件于$x$的y的统计值。这样特例化的损失函数使得我们可以训练这些估计的预算子。  

完整训练神经网络的损失函数通常是一个主损失函数和一个正则项(regularization)的组合。线性模型中使用的权值衰减(weight decay)也同样可以适用于深度神经网络，也是目前最流行的正则化策略。  

#### 使用最大似然学习条件分布
大部分现代神经网络都是使用最大似然来训练的，那么损失函数就是log-likelihood的负值形式。这个等同于描述为训练集数据和模型分布之间的交叉熵。以下就是神经网络的损失函数：  

$$J(\theta) = - \mathbb{E}_{x,y\sim \hat{p_{data}}}\log p_{model}(y|x)$$
这个损失函数的具体形式会随着不同的模型而改变，具体的变化还是在于$\log p_{model}$的形式。上述公式的展开会得到一些与模型参数无关项，而这些就是可以被忽略的。我们就以$p_{model}(y | x)=\mathcal{N}(y; f(x;\theta), I)$为例子，损失函数就可以展开为如下形式：  

$$J(\theta) = \frac{1}{2} \mathbb{E}_{x,y\sim \hat{p_{data}}}\lVert y - f(x;\theta)\lVert^2 + const$$

其中$\frac{1}{2}$系数和不依赖于$\theta$的计算项。正如我们所知道的，输出分布的最大似然估计和线性模型的MSE之间的等效性。但是事实上这个等效性是跟选择的函数$f(x;\theta)$无关。对最大似然损失函数进行求导减少对模型设计损失函数的负担。指定一个模型$p(y|x)$就自动了确定了一个损失函数$\log p(y|x)$。  

在神经网络的设计中，我们需要损失函数的梯度比较大以及有足够的预测能力来引导整个的学习。饱和(saturate)的函数会破坏这个目标，因为它会使梯度比较小。在很多情况下还是会发生这种情况的。因为隐藏层的激活函数或者输出单元是饱和的。对于很多模型，负对数似然(negative log-likelihood)有助于避免这个问题。很多输出单元会涉及到exp函数，而它在参数高负值的时候就是饱和的。对数函数能够抵消输出单元的exp。这里我们可以看出损失函数和输出单元的选择是有联系的。  

在实际模型的应用中，用于进行最大似然估计的交叉熵损失有一个不寻常特性就是通常没有一个最小值。对于离散的输出变量，大多数模型是以无法表示0或者1概率的方式来参数化的，但是可以实现任意的接近。逻辑回归就是这样一个例子。对于实数输出变量，如果模型能够控制输出分布的密度，那么就有该正确的训练集输出赋予较高的密度。这样就会导致交叉熵会接近负无穷大。这里我们就需要使用正则化技术来避免模型获得这样方式所带来的无限量奖励。  

##### 学习条件统计值

不同于学习一个全概率分布$p(y|x;\theta)$，通常我们想要学习给定$x$对应$y$的条件统计值。例如我们有一个预测算子$f(x; \theta)$用于预测$y$的均值。  

如果我们使用一个足够强大的神经网络，可以认为它就有能力表示一个较大范围类型的函数。这里的函数类型只会由连续性和上下界等特征来限制，而不会有特定的参数形式。从这点来看。我们可以认为损失函数就是一个泛函，而不只是一个函数。一个泛函就是一个将函数到实数的映射。所以学习就是选择函数，而不是选择参数集。我们可以设计损失泛函在特定函数有它的最小值。例如我们设计损失泛函在某个函数上有其最小值，而这个函数将$x$映射到给定$x$对应$y$的期望值上。解一个关于函数的优化问题需要一个叫变分法(calculus of variations)的数学工具。当然目前没有必要完全理解这个变分法，而只需要知道可以使用变分法来推出以下的两个结果。  

第一个结果就是解决如下优化问题：  
$$f^*=\arg \min_f \mathbb{E}_{x,y\sim p_{data}} \lVert y - f(x)\lVert^2$$
只要目标函数在我们优化覆盖的类别中，就可以生成如下等式：  
$$f^*=\mathbb{E}_{x,y\sim p_{data}(y|x)} [y]$$
也就是说如果我们可以从真实数据分布中训练无限多的样本，可以由最小化MSE损失函数学习出一个预测给定$x$对应$y$均值的函数。不同损失函数给出不同的统计值。  
使用变分法的第二个结果就是只要可以被我们优化函数族来描述，如下等式就可以学习一个函数来预测$y$的中值(median value)。这个函数通常被称为平均绝对误差(mean absolute error)。  

不幸运地是MSE和MAE在基于梯度的优化中经常会导致较差的结果。一些饱和的输出单元与这些损失函数结合在一起时会产生非常小的梯度。这就是为什么即使在没有必要估计一个完成分布$p(y|x)$时交叉熵也比它们更流行的原因。  

#### 输出单元
损失函数的选择与输出单元的选择联系紧密。绝大部分时候我们可以在真实数据分布和模型分布之间使用交叉熵。如何表示输出决定了交叉熵的形式。任何类型的神经网络单元都可以被用于作为输出单元或者隐藏单元。输出层的作用就是就是对特征进行最后的转化来完成任务。  

##### 针对高斯输出分布的线性单元
基于一个线性仿射变换的输出单元就是一种较为简单的输出单元。通常我们就直接称它为线性单元(linear units)。给定特征$h$，线性单元层会产生一个向量$\hat{y}=W^Th + b$。线性单元层通常被用来生成条件高斯分布的均值：  
$$p(y|x)=\mathcal{N}(y;\hat{y}, I)$$
这里最大化对数似然率则等同于最小化均值平方差(MSE)。可以使用最大似然框架来学习高斯的方差，但是这里方差必需被限制为所有输入的正定矩阵。在实践中这个限制是很难满足的，所以通常会使用其他的输出单元来参数化方差。下文我们会简单地介绍一下如何对方差建模。由于线性单元的不饱和性，所以可以广泛地应用到基于梯度的优化算法中。  

一个Sigmoid输出单元采用如下方式来定义
$$\hat{y}=\sigma(w^Th+b)$$
其中$\sigma$就是logistic sigmoid函数：$\sigma(x)=\frac{1}{1+e^{-x}}$。  
我们可以认为sigmoid输出单元有两个组成部分。首先它使用了一个线性层来计算$z=w^Th + b$。然后它使用了sigmoid激活函数将$z$转换成一个概率值。  

这里我们先跳过$x$来直接讨论如何使用$z$来定义关于$y$的概率分布。Sigmoid可以使用一个没有经过规范化的分布$\hat{P}(y)$，也就是这个分布的概率总和不为1。为了实现规范化，可以通过除以一个常数。



##### 针对Bernoulli输出分布的Sigmoid单元
许多任务要求对二进制的值进行预测，例如二分类问题。最大似然方法就是用来定义条件于$x$的$y$Bernoulli分布。一个Bernoulli分布可以被单一的数来定义。神经网络只需要用来预测$P=(y=1 | x)$。而这个数的取值就在范围$[0, 1]$之间。  

为了满足这个条件，我们需要进行一些设计。假定我们使用一个线性单元。通过阈值化可以得到一个有效的概率值。  
$$P(y=1|x) = max\{0, min\{1, w^Th + b\}\}$$
但是这个方法是无法使用梯度下降的办法来训练的。一旦$w^Th+b$的取值超出了$[0,1]$的范围，那么梯度就会是0。这样就无法继续训练下去了。  

所以我们需要采用其他的办法来确保即使模型产生了错误的值，它总是有较好的梯度。而这个办法就是使用结合了最大似然的Sigmoid输出单元。



一个Sigmoid输出单元采用如下方式来定义
$$\hat{y}=\sigma(w^Th+b)$$
其中$\sigma$就是logistic sigmoid函数：$\sigma(x)=\frac{1}{1+e^{-x}}$。  
我们可以认为sigmoid输出单元有两个组成部分。首先它使用了一个线性层来计算$z=w^Th + b$。然后它使用了sigmoid激活函数将$z$转换成一个概率值。  

这里我们先跳过$x$来直接讨论如何使用$z$来定义关于$y$的概率分布。Sigmoid可以使用一个没有经过规范化的分布$\hat{P}(y)$，也就是这个分布的概率总和不为1。为了实现规范化，可以通过除以一个常数。

# Reference
[1] [RBF核函数](http://baike.baidu.com/link?url=P35OBfXNjmZEysUJFLmelk_UjnR9Vu7hwybcCJrevqNkSe5gUufN8Hb8M8pxBuFpS9K6ljlS_wvJoHEYjsKieqtlOnit4gJVkU_45nDE4xH6KOdw6fyDGDDn20E1deuG6jweic_IeeAVQZv0BD4W__):   
[2] [Non-convex and convex]():  
[3] [最大似然估计和最小二乘的理解](https://www.zhihu.com/question/20447622)， [最大似然估计的介绍](https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1)  
[4] [交叉熵损失函数](http://blog.csdn.net/u012162613/article/details/44239919): $C=-\frac{1}{n} \sum_{x} [y\ln a + (1-y)\ln(1 - a)]$将损失函数的梯度由依赖于目标函数$\sigma(x)$的梯度转成依赖于预测的误差$\sigma(x) - y$。这样就使得误差大的时候更新的比较块，误差小的时候更新慢。对数似然函数长用来作为softmax回归的损失函数。如果使使用sigmoid函数，那么就采用交叉熵损失函数。而在二类别时最大对数似然损失函数可以化简为交叉熵损失函数的形式。  
[5] [neural networks and deep learning](http://neuralnetworksanddeeplearning.com/)  
[6] 平均绝对误差: 统计学上用于评价预测值与真实值的接近程度。$$MAE=\frac{1}{n} \sum_{i=1}^n \vert f_i - y_i\vert $$  
[7] 

